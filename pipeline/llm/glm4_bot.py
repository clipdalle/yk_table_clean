"""
GLM-4 API è°ƒç”¨ï¼ˆç±»å°è£…ï¼‰
å®‰è£…ä¾èµ–ï¼špip install requests
"""

import requests
import json
import sys
import os
from typing import List
from tenacity import retry, stop_after_attempt, wait_fixed

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if project_root not in sys.path:
    sys.path.append(project_root)


from pipeline.llm.base import BaseLLMClient


class GLM4Client(BaseLLMClient):
    """
    GLM-4 API å®¢æˆ·ç«¯
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    æœ¬ç±»å®ç°äº† 2 ä¸ªæ ¸å¿ƒæ–¹æ³•ï¼š
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    1. get_available_api_keys() - è¿”å›é…ç½®çš„ GLM-4 API key
    2. _get_completion_with_key() - ä½¿ç”¨æŒ‡å®š key è°ƒç”¨ GLM-4 API
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    åŸºç±»è‡ªåŠ¨æä¾›ï¼ˆæ— éœ€å®ç°ï¼‰ï¼š
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    - get_completion() - å•æ¬¡è¯·æ±‚
    - get_completion_json() - å•æ¬¡ JSON è¯·æ±‚
    - batch_get_completions() - æ‰¹é‡å¹¶è¡Œè¯·æ±‚
    - batch_get_completions_json() - æ‰¹é‡ JSON è¯·æ±‚
    """
    
    def __init__(
        self, 
        max_tokens: int = 2000
    ):
        """
        åˆå§‹åŒ– GLM-4 å®¢æˆ·ç«¯ï¼ˆè‡ªåŠ¨è·å–å¯ç”¨çš„ API keysï¼‰
        
        Args:
            model: æ¨¡å‹åç§°ï¼ˆglm-4-flash, glm-4-plus, glm-4-air ç­‰ï¼‰
            api_url: API åœ°å€
            max_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
        """
        super().__init__()  # è‡ªåŠ¨è·å– API keys
        
        self.model_name = "glm-4-plus"
        self.api_url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        self.max_tokens = max_tokens
        
        print(f"ğŸ”‘ å·²åŠ è½½ {len(self.api_keys)} ä¸ª API keys")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.model_name}")
    
    @classmethod
    def get_available_api_keys(cls) -> List[str]:
        """
        è·å–å¯ç”¨çš„ GLM-4 API keys
        
        Returns:
            List[str]: å¯ç”¨çš„ API key åˆ—è¡¨
        """
        # GLM-4 é€šå¸¸åªæœ‰ä¸€ä¸ª keyï¼Œä»é…ç½®æ–‡ä»¶è¯»å–
        GLM4_API_KEY_LIST = [
            '4e51ecf7fcae4bed90edf3b9d4a026a7.XdH96shx1QedVUqb',  # æ™ºè°± GLM-4 API Key
            'f861430f05c0415a915d2c9d7b1e06e5.CkSoQmKgQySRlPDc'  # æ™ºè°± GLM-4 API Key
        ]
        return GLM4_API_KEY_LIST
    
    @retry(stop=stop_after_attempt(3), wait=wait_fixed(1), reraise=True)
    def _get_completion_with_key(
        self, 
        prompt: str, 
        api_key: str,
        temperature: float = 0.7
    ) -> str:
        """
        ä½¿ç”¨æŒ‡å®šçš„ API key è°ƒç”¨ GLM-4 APIï¼ˆè‡ªåŠ¨é‡è¯•3æ¬¡ï¼‰
        
        Args:
            prompt: è¾“å…¥çš„æç¤ºè¯
            api_key: è¦ä½¿ç”¨çš„ API key
            temperature: æ¸©åº¦å‚æ•°ï¼Œ0-1ä¹‹é—´ï¼Œè¶Šé«˜è¶Šéšæœº
        
        Returns:
            str: æ¨¡å‹è¿”å›çš„æ–‡æœ¬å†…å®¹
            
        Raises:
            Exception: å¦‚æœ3æ¬¡é‡è¯•åä»ç„¶å¤±è´¥
        """
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model_name,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": temperature,
            "max_tokens": self.max_tokens,
            "stream": False,
            "do_sample": True
        }
        
        response = requests.post(
            self.api_url,
            headers=headers,
            json=payload,
            timeout=60
        )
        
        response.raise_for_status()
        
        result = response.json()
        
        # æå–è¿”å›çš„æ–‡æœ¬
        if 'choices' in result and len(result['choices']) > 0:
            return result['choices'][0]['message']['content']
        else:
            raise ValueError(f"æœªæ‰¾åˆ°è¿”å›å†…å®¹ - {result}")
    
    # ä»¥ä¸‹æ–¹æ³•ç”±åŸºç±»è‡ªåŠ¨æä¾›ï¼š
    # - get_completion() - å•æ¬¡è¯·æ±‚
    # - get_completion_json() - å•æ¬¡ JSON è¯·æ±‚
    # - batch_get_completions() - æ‰¹é‡å¹¶è¡Œè¯·æ±‚
    # - batch_get_completions_json() - æ‰¹é‡ JSON è¯·æ±‚


# -------- æµ‹è¯•ç¤ºä¾‹ --------
if __name__ == '__main__':
    # è‡ªåŠ¨è·å–å¯ç”¨çš„ API keys
    client = GLM4Client()
    
    # # æµ‹è¯•å•æ¬¡è¯·æ±‚
    # test_prompt = "ç”¨ä¸€å¥è¯ä»‹ç»ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ "
    # result = client.get_completion(test_prompt)
    # print('\n--- GLM-4 å•æ¬¡è¯·æ±‚ ---')
    # print(result)
    
    # æµ‹è¯•æ‰¹é‡è¯·æ±‚
    test_prompts = [
        "ç”¨ä¸€å¥è¯ä»‹ç»ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ",
        "ç”¨ä¸€å¥è¯ä»‹ç»ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ",
        "ç”¨ä¸€å¥è¯ä»‹ç»ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†"
    ]
    results = client.batch_get_completions(test_prompts)
    print('\n--- GLM-4 æ‰¹é‡è¯·æ±‚ ---')
    for i, (prompt, response) in enumerate(zip(test_prompts, results), 1):
        print(f"{i}. {prompt}")
        print(f"   {response}\n")
